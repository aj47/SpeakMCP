
> speakmcp@0.1.3 dev /Users/ajjoobandi/Development/SpeakMCP
> electron-vite dev --watch -- "d"

vite v5.4.19 building SSR bundle for development...

watching for file changes...

build started...
transforming...
✓ 409 modules transformed.
rendering chunks...
out/main/emergency-stop-DHsAbVAp.js           0.63 kB
out/main/oauth-callback-server-fzqzUOMc.js    6.84 kB
out/main/models-service-f1-vHHIr.js          14.01 kB
out/main/index.js                           250.59 kB
out/main/updater-BDiG8kM8.js                475.46 kB
built in 821ms.

build the electron main process successfully

-----

vite v5.4.19 building SSR bundle for development...

watching for file changes...

build started...
transforming...
✓ 2 modules transformed.
rendering chunks...
out/preload/index.mjs  2.93 kB
built in 9ms.

build the electron preload files successfully

-----

dev server running for the electron renderer process at:

  ➜  Local:   http://localhost:5173/
  ➜  Network: use --host to expose

start electron app...

[DEBUG] Enabled: LLM, TOOLS, KEYBINDS, APP (argv: d)
[2025-09-04T14:39:46.446Z] [DEBUG][APP] SpeakMCP starting up...
[2025-09-04T14:39:46.446Z] [DEBUG][APP] Deep link handling initialized
[2025-09-04T14:39:46.465Z] [DEBUG][APP] Accessibility granted: true
[2025-09-04T14:39:46.467Z] [DEBUG][APP] Application menu created
[2025-09-04T14:39:46.467Z] [DEBUG][APP] IPC main registered
[2025-09-04T14:39:46.480Z] [DEBUG][APP] Serve protocol registered
[2025-09-04T14:39:46.481Z] [DEBUG][APP] Creating main window...
[2025-09-04T14:39:46.539Z] [DEBUG][APP] Main window created
[2025-09-04T14:39:46.539Z] [DEBUG][APP] Creating panel window...
[2025-09-04T14:39:46.555Z] [DEBUG][APP] Panel window created
[2025-09-04T14:39:46.558Z] [DEBUG][KEYBINDS] Starting keyboard event listener with rdev path: /Users/ajjoobandi/Development/SpeakMCP/resources/bin/speakmcp-rs
[2025-09-04T14:39:46.558Z] [DEBUG][APP] Keyboard event listener started
[2025-09-04T14:39:46.569Z] [DEBUG][APP] System tray initialized
[2025-09-04T14:39:46.570Z] [DEBUG][TOOLS] MCP Service initialization starting
[2025-09-04T14:39:46.570Z] [DEBUG][TOOLS] Skipping server desktop-commander - runtime disabled by user
[2025-09-04T14:39:46.570Z] [DEBUG][TOOLS] Found 2 servers to initialize [ 'github', 'rube' ]
[2025-09-04T14:39:46.570Z] [DEBUG][TOOLS] Starting initialization of server: github
[2025-09-04T14:39:46.571Z] [DEBUG][TOOLS] Initializing server: github {
  transport: 'stdio',
  command: 'npx',
  args: [ '-y', '@modelcontextprotocol/server-github' ],
  env: [ 'GITHUB_PERSONAL_ACCESS_TOKEN' ]
}
Skip checkForUpdates because application is not packed and dev update config is not forced
Skip checkForUpdates because application is not packed and dev update config is not forced
[2025-09-04T14:39:47.827Z] [DEBUG][TOOLS] Server github connected successfully {
  toolCount: 26,
  tools: [
    {
      name: 'create_or_update_file',
      description: 'Create or update a single file in a GitHub repository'
    },
    {
      name: 'search_repositories',
      description: 'Search for GitHub repositories'
    },
    {
      name: 'create_repository',
      description: 'Create a new GitHub repository in your account'
    },
    {
      name: 'get_file_contents',
      description: 'Get the contents of a file or directory from a GitHub repository'
    },
    {
      name: 'push_files',
      description: 'Push multiple files to a GitHub repository in a single commit'
    },
    {
      name: 'create_issue',
      description: 'Create a new issue in a GitHub repository'
    },
    {
      name: 'create_pull_request',
      description: 'Create a new pull request in a GitHub repository'
    },
    {
      name: 'fork_repository',
      description: 'Fork a GitHub repository to your account or specified organization'
    },
    {
      name: 'create_branch',
      description: 'Create a new branch in a GitHub repository'
    },
    {
      name: 'list_commits',
      description: 'Get list of commits of a branch in a GitHub repository'
    },
    {
      name: 'list_issues',
      description: 'List issues in a GitHub repository with filtering options'
    },
    {
      name: 'update_issue',
      description: 'Update an existing issue in a GitHub repository'
    },
    {
      name: 'add_issue_comment',
      description: 'Add a comment to an existing issue'
    },
    {
      name: 'search_code',
      description: 'Search for code across GitHub repositories'
    },
    {
      name: 'search_issues',
      description: 'Search for issues and pull requests across GitHub repositories'
    },
    { name: 'search_users', description: 'Search for users on GitHub' },
    {
      name: 'get_issue',
      description: 'Get details of a specific issue in a GitHub repository.'
    },
    {
      name: 'get_pull_request',
      description: 'Get details of a specific pull request'
    },
    {
      name: 'list_pull_requests',
      description: 'List and filter repository pull requests'
    },
    {
      name: 'create_pull_request_review',
      description: 'Create a review on a pull request'
    },
    { name: 'merge_pull_request', description: 'Merge a pull request' },
    {
      name: 'get_pull_request_files',
      description: 'Get the list of files changed in a pull request'
    },
    {
      name: 'get_pull_request_status',
      description: 'Get the combined status of all status checks for a pull request'
    },
    {
      name: 'update_pull_request_branch',
      description: 'Update a pull request branch with the latest changes from the base branch'
    },
    {
      name: 'get_pull_request_comments',
      description: 'Get the review comments on a pull request'
    },
    {
      name: 'get_pull_request_reviews',
      description: 'Get the reviews on a pull request'
    }
  ]
}
[2025-09-04T14:39:47.828Z] [DEBUG][TOOLS] Successfully initialized server: github
[2025-09-04T14:39:47.828Z] [DEBUG][TOOLS] Starting initialization of server: rube
[2025-09-04T14:39:47.828Z] [DEBUG][TOOLS] Initializing server: rube {
  transport: 'streamableHttp',
  command: undefined,
  args: undefined,
  env: []
}
[2025-09-04T14:39:47.952Z] [DEBUG][KEYBINDS] Ctrl key pressed, isPressedCtrlKey = true
[2025-09-04T14:39:47.953Z] [DEBUG][KEYBINDS] Config change #1: {
  agentKillSwitchEnabled: true,
  agentKillSwitchHotkey: 'ctrl-shift-q',
  textInputEnabled: true,
  textInputShortcut: 'ctrl-t',
  mcpToolsEnabled: true,
  mcpToolsShortcut: 'hold-ctrl-alt',
  shortcut: undefined
}
[2025-09-04T14:39:48.271Z] [DEBUG][KEYBINDS] Text input triggered: Ctrl+T
Skip checkForUpdates because application is not packed and dev update config is not forced
[2025-09-04T14:39:48.418Z] [DEBUG][KEYBINDS] Ctrl key released, isPressedCtrlKey = false
[2025-09-04T14:39:49.663Z] [DEBUG][TOOLS] Server rube connected successfully {
  toolCount: 7,
  tools: [
    {
      name: 'RUBE_CREATE_PLAN',
      description: '\n' +
        'This is a workflow builder that ensures the LLM produces a complete, step-by-step plan for any use case.\n' +
        "You MUST always call this tool after RUBE_SEARCH_TOOLS or RUBE_MANAGE_CONNECTIONS to get a proper execution plan for the user's use case.\n" +
        'If the user pivots to a different use case in same chat, you MUST call this tool again with the new use case.\n' +
        '\n' +
        'Outputs a complete plan with sections such as "workflow_steps", "complexity_assessment", "decision_matrix", "failure_handlig" "output_format", and more as needed. \n' +
        '\n' +
        'If you skip this step, workflows will likely be incomplete, or fail during execution for complex tasks.\n' +
        'Calling it guarantees reliable, accurate, and end-to-end workflows aligned with the available tools and connections.\n'
    },
    {
      name: 'RUBE_MULTI_EXECUTE_TOOL',
      description: '\n' +
        '  Fast and parallel tool executor for tools discovered through RUBE_SEARCH_TOOLS. Use this tool to execute upto 20 tools in parallel across apps. Response contains structured outputs ready for immediate analysis - avoid reprocessing via remote bash/code execute tools.\n' +
        '  \n' +
        '  Prerequisites:\n' +
        '- Ensure usage of valid tool slugs and their parameters discovered through RUBE_SEARCH_TOOLS.\n' +
        '- Active connection statuses for the tools that are going to be executed through RUBE_MANAGE_CONNECTIONS.\n' +
        '- Ensure proper plan creation using RUBE_CREATE_PLAN has been done.\n' +
        '- Cannot have any dependency of the response among the tools.\n' +
        '\n' +
        'Usage guidelines:\n' +
        '- To be used whenever a tool is discovered and has to be called, either as part of a multi-step workflow or as a standalone tool.\n' +
        '- If RUBE_SEARCH_TOOLS returns a tool that can perform the task, prefer calling it via this executor AFTER consulting RUBE_CREATE_PLAN. Do not write custom API calls or ad‑hoc scripts for tasks that can be completed by available Composio tools.\n' +
        '- Tools should be used highly parallelly.\n' +
        '- Predictively set sync_response_to_workbench=true if the response may be large or needed for later scripting. It still shows inline. However, if the actual response data turns out small and manageable without scripting, SKIP the workbench and use inline response directly.\n' +
        '- Responses contain structured outputs for each tool. RULE: Small data - process yourself inline; large data - process in the workbench.\n' +
        '- ALWAYS include inline references/links to sources in MARKDOWN format directly next to the relevant text. Eg provide slack thread links along with summary. \n'
    },
    {
      name: 'RUBE_REMOTE_BASH_TOOL',
      description: '\n' +
        '  Execute bash commands in a REMOTE sandbox for file operations, data processing, and system tasks. Essential for handling large tool responses saved to remote files.\n' +
        '  PRIMARY USE CASES:\n' +
        '- Process large tool responses saved to remote sandbox\n' +
        '- File system operations, data processing with shell tools like jq, awk, sed, grep, etc.\n' +
        '\n' +
        'WORKFLOW INTEGRATION:\n' +
        '1. IF RUBE_MULTI_EXECUTE_TOOL saves large responses to remote sandbox\n' +
        '3. Extract specific information from JSON files using jq\n' +
        '\n' +
        'IMPORTANT NOTES:\n' +
        '- Commands run from /home/user directory by default\n'
    },
    {
      name: 'RUBE_REMOTE_WORKBENCH',
      description: '\n' +
        "  Process REMOTE FILES or script BULK TOOL EXECUTIONS using Python code IN A REMOTE SANDBOX. If you can see the data in chat, DON'T USE THIS TOOL.   \n" +
        '**ONLY** use this when processing **data stored in a remote file** or when scripting bulk Composio tool executions or proxy_execute calls (when no direct Composio tool exists for the task).  \n' +
        '\n' +
        'DO NOT USE\n' +
        '- When the complete response is already inline/in-memory, or you only need quick parsing, summarization, or basic math.\n' +
        '\n' +
        'USE IF\n' +
        '- To parse/analyze tool outputs saved to a remote file in the sandbox or to script multi-tool chains there.\n' +
        '- For bulk or repeated executions of known Composio tools (e.g., add a label to 100 emails).\n' +
        '- To call APIs via proxy_execute when no Composio tool exists for that API.\n' +
        '\n' +
        'OUTPUTS\n' +
        '- Returns a compact result and, if too long, path(s) to artifacts under `/home/user/.code_out`.\n' +
        '\n' +
        'IMPORTANT CODING RULES: \n' +
        '  1. Stepwise Execution: Prefer splitting work into small steps. Save intermediate outputs in variables or temporary file in `/tmp/`. Call RUBE_REMOTE_WORKBENCH again for the next step. This improves composabilit and avoid timeouts.\n' +
        '  1. Notebook Persistence: This is a persistent Jupyter notebook cell: variables, functions, imports, and in-memory state from previous and future code executions are preserved in the notebook’s history and available for ruse. You also have a few helper functions available.\n' +
        '  3. Parallelism & Timeout (CRITICAL): There is a hard timeout of 4 minutes so complete the code within that. Prioritize PARALLEL execution using ThreadPoolExecutor with suitable concurrency for bulk operations - e.g., call run_composio_tool or invoke_llm parallelly across rows to maximize efficiency. \n' +
        '    3.1 If the data is large, split into smaller batches and call the workbench multiple times.\n' +
        '  4. Checkpoints: Implement checkpoints (in memory or files) so that long runs can be resumed from the last completed step.\n' +
        '  5. Schema Safety: Never assume the response schema for run_composio_tool if not known already from previous tools. To inspect schema, either run a simple request **outside** the workbench via RUBE_MULTI_EXECUTE_TOOL or use invoke_llm helper.\n' +
        '  6. LLM Helpers: You should always use invoke_llm helper for summary, analysis, or field extraction on results. This is a smart LLM that will give much better results than any adhoc filtering.\n' +
        '  7. Avoid Meta Loops: Do not use run_composio_tool to call RUBE_MULTI_EXECUTE_TOOL or other RUBE_* meta tools to avoid cycles. Only use it for app tools. \n' +
        '  8. Pagination: Use when data spans multiple pages. Continue fetching pages with the returned next_page_token or cursor until none remains. Parallelize fetching pages if tool supports page_number.\n' +
        '  9. No Hardcoding: Never hardcode data in code. Always load it from files or tool responses, iterating to construct intermediate or final inputs/outputs.\n' +
        '  10. Code Correctness (CRITICAL): Code must be syntactically and semantically correct and executable.\n' +
        '\n' +
        'ENV & HELPERS:\n' +
        '1. Home directory: `/home/user`.\n' +
        '4. Helper functions initialized in the workbench:\n' +
        '    1) `run_composio_tool(tool_slug: str, arguments: dict)`: Execute a known Composio **app** tool (from RUBE_SEARCH_TOOLS). Do not invent names; match the tool’s input schema. Suited for loops/parallel/bulk over datasets. \n' +
        '      1.1 run_composio_tools returns JSON with top-level "data". Parse carefully—structure may be nested.\n' +
        '    2) `invoke_llm(query: str)`: Invoke an LLM for semantic tasks. Pass MAX 50000 characters in input.\n' +
        '    3) `proxy_execute(method, endpoint, toolkit, params=None, body=None)`: Call a toolkit API directly when no Composio tool exists.\n' +
        '    4) `web_search(query: str)`: Search the web for information.\n' +
        '    5) `upload_local_file(*file_paths)`: Upload files to Composio S3/R2 storage. Use this when you need to upload/download any generated artifacts from the sandbox.\n' +
        '\n' +
        '\n' +
        '## Python Helper Functions for LLM Scripting\n' +
        '\n' +
        '### 1) run_composio_tool(tool_slug, arguments)\n' +
        'Executes a known Composio tool via backend API. Do NOT call RUBE_* meta tools to avoid cyclic calls.\n' +
        '\n' +
        '    def run_composio_tool(tool_slug: str, arguments: Dict[str, Any]) -> tuple[Dict[str, Any], str]\n' +
        '    # Returns: (tool_response_dict, error_message)\n' +
        '    #   Success: ({"data": {actual_data}}, "") - Note the top-level data\n' +
        '    #   Error:   ({}, "error_message") or (response_data, "error_message")\n' +
        '\n' +
        '    result, error = run_composio_tool("GMAIL_FETCH_EMAILS", {"max_results": 1, "user_id": "me"})\n' +
        '    if error:\n' +
        '        print("GMAIL_FETCH_EMAILS error:", error); return\n' +
        '    email_data = result.get("data", {})\n' +
        '    print("Fetched:", email_data)\n' +
        '\n' +
        '### 2) invoke_llm(query)\n' +
        'Calls Groq LLM for reasoning, analysis, and semantic tasks. Pass MAX 50000 characters input.\n' +
        '\n' +
        '    def invoke_llm(query: str) -> tuple[str, str]\n' +
        '    # Returns: (llm_response, error_message)\n' +
        '\n' +
        '    resp, error = invoke_llm("Summarize the key points from this data")\n' +
        '    if error:\n' +
        '        print("invoke_llm error:", error); return\n' +
        '    print("LLM:", resp)\n' +
        '\n' +
        '    # Example: analyze tool response with LLM\n' +
        '    tool_resp, err = run_composio_tool("GMAIL_FETCH_EMAILS", {"max_results": 5, "user_id": "me"})\n' +
        '    if err:\n' +
        '        print("GMAIL_FETCH_EMAILS error:", err); return\n' +
        '    parsed = tool_resp.get("data", {})\n' +
        '    resp, err = invoke_llm(f"Analyze these emails and summarize: {parsed}")\n' +
        '    if err:\n' +
        '        print("invoke_llm error:", err); return\n' +
        '    print("LLM Gmail Summary:", resp)\n' +
        '\n' +
        '    # TIP: batch prompts to reduce LLM calls.\n' +
        '\n' +
        '### 4) proxy_execute(method, endpoint, toolkit, params=None, body=None)\n' +
        'Direct API call to a connected toolkit service.\n' +
        '\n' +
        '    from typing import Literal, Optional\n' +
        '\n' +
        '    def proxy_execute(\n' +
        '        method: Literal["GET","POST","PUT","DELETE","PATCH"],\n' +
        '        endpoint: str,\n' +
        '        toolkit: str,\n' +
        '        params: Optional[list[Parameter]] = None,\n' +
        '        body: Optional[object] = None,\n' +
        '    ) -> tuple[ToolProxyResponse | None, str]\n' +
        '    # Returns: (response_object, error_message)\n' +
        '\n' +
        '    response, error = proxy_execute("GET", "https://api.github.com/repos/owner/repo", "github")\n' +
        '    if error:\n' +
        '        print("proxy_execute error:", error); return\n' +
        '    print("Success:", response.data)\n' +
        '\n' +
        '### 5) web_search(query)\n' +
        'Searches the web via Exa AI.\n' +
        '\n' +
        '    def web_search(query: str) -> tuple[str, str]\n' +
        '    # Returns: (search_results_text, error_message)\n' +
        '\n' +
        '    results, error = web_search("latest developments in AI")\n' +
        '    if error:\n' +
        '        print("web_search error:", error)\n' +
        '    else:\n' +
        '        print("Results:", results)\n' +
        '\n' +
        '## Best Practices\n' +
        '\n' +
        '### Error-first pattern\n' +
        '    data, error = some_helper(...)\n' +
        '    if error:\n' +
        '        print("some_helper error:", error); return\n' +
        '    # safe to use `data`\n' +
        '\n' +
        '### Defensive parsing (print keys while narrowing)\n' +
        '    res, err = run_composio_tool("GMAIL_FETCH_EMAILS", {"max_results": 5})\n' +
        '    if not err and isinstance(res, dict):\n' +
        '        print("res keys:", list(res.keys()))\n' +
        '        data = res.get("data") or {}\n' +
        '        print("data keys:", list(data.keys()))\n' +
        '        msgs = data.get("messages") or []\n' +
        '        print("messages count:", len(msgs))\n' +
        '        for m in msgs:\n' +
        '            print("subject:", m.get("subject", "<missing>"))\n' +
        '\n' +
        '### Parallelize (4-min sandbox timeout)\n' +
        'Adjust concurrency so all tasks finish within 4 minutes.\n' +
        '\n' +
        '    import concurrent.futures\n' +
        '\n' +
        '    MAX_CONCURRENCY = 10 # Adjust as needed\n' +
        '\n' +
        '    def send_bulk_emails(email_list):\n' +
        '        def send_single(email):\n' +
        '            result, error = run_composio_tool("GMAIL_SEND_EMAIL", {\n' +
        '                "to": email["recipient"], "subject": email["subject"], "body": email["body"]\n' +
        '            })\n' +
        '            if error:\n' +
        `                print(f"Failed {email['recipient']}: {error}")\n` +
        '                return {"status": "failed", "error": error}\n' +
        '            return {"status": "sent", "data": result}\n' +
        '\n' +
        '        results = []\n' +
        '        with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_CONCURRENCY) as ex:\n' +
        '            futures = [ex.submit(send_single, e) for e in email_list]\n' +
        '            for f in concurrent.futures.as_completed(futures):\n' +
        '                results.append(f.result())\n' +
        '        return results\n' +
        '\n' +
        '    # Example usage\n' +
        '    email_list = [{"recipient": f"user{i}@example.com", "subject": "Test", "body": "Hello"} for i in range(1000)]\n' +
        '    results = send_bulk_emails(email_list)\n' +
        '\n' +
        '### upload_local_file(*file_paths)\n' +
        'Uploads files to Composio S3/R2 storage. Single files upload directly, multiple files are auto-zipped.\n' +
        'Use this when you need to upload/download any generated artifacts from the sandbox.\n' +
        '\n' +
        '    def upload_local_file(*file_paths) -> tuple[Dict[str, Any], str]\n' +
        '    # Returns: (result_dict, error_string)\n' +
        '    # Success: ({"s3_url": str, "uploaded_file": str, "type": str, "id": str, "key": str, "message": str}, "")\n' +
        '    # Error: ({}, "error_message")\n' +
        '\n' +
        '    # Single file\n' +
        '    result, error = upload_local_file("/path/to/report.pdf")\n' +
        '    \n' +
        '    # Multiple files (auto-zipped)\n' +
        '    result, error = upload_local_file("/home/user/doc1.txt", "/home/user/doc2.txt")\n' +
        '    \n' +
        '    # Always check for errors\n' +
        '    if error:\n' +
        '        print("Upload failed:", error)\n' +
        '        return\n' +
        '    print("Uploaded:", result["s3_url"])\n' +
        '\n' +
        '\n' +
        'Guidance: Ensure to peform the task with High Accuracy and Completeness. For large data, use parallel processing (ThreadPoolExecutor) and fewer batches in each call to maximise efficiency. Leverage invoke_llm for smart analysis whenever needed. NEVER hardcode data in code and NEVER run RUBE_MULTI_EXECUTE_TOOL in the workbench.\n'
    },
    {
      name: 'RUBE_SEARCH_TOOLS',
      description: '\n' +
        '  MCP Server Info: Rube MCP by Composio connects 500+ apps—Slack, GitHub, Notion, Google Workspace (Gmail, Sheets, Drive, Calendar), Microsoft (Outlook, Teams), X, Figma, Meta apps (WhatsApp, Instagram), TikTok, AI tools like Veo3 & V0, and more—for seamless cross-app automation. \n' +
        '  Use this MCP server to discover new tools and connect to apps. \n' +
        '  ALWAYS call this tool first whenever a user mentions or implies an external app, service, or workflow—never say "I don’t have access to X/Y app" before calling it.\n' +
        '\n' +
        '<br>\n' +
        '  Tool Info: Extremely fast search tool to discover available MCP callable tools that can be used to solve a particular problem, user query or complete a task.\n' +
        'Usage guidelines:\n' +
        '  <recommended>\n' +
        '  - Use this tool whenever kicking off a task. Post this, keep coming back to this tool to discover new tools.\n' +
        '  - If the user pivots to a different use case in same chat, you MUST call this tool again with the new use case.\n' +
        '  </recommended>\n' +
        '  - Specify the use_case with a detailed description of the problem, query, or task. Be clear and precise so the system can find the most relevant tools. Queries can involve one or multiple apps, and be simple or complex—from a quick action to a multi-step, cross-app workflow.\n' +
        '  - Pass known_fields as a list of key-value pairs to help the search provide tools to look up missing details (for example, finding channel_id from a given channel_name). \n' +
        '  - To understand the abilities and skills at hand, set exploratory_query to true. Otherwise, keep it as false for task specific searches.\n' +
        '  - After this tool, call RUBE_CREATE_PLAN to ensure proper plan creation.\n' +
        'Response: \n' +
        '  - The response is a list of toolkits (apps) and tools suitable for the task, along with their tool_slug, description, input schema, and related tools that may serve as prerequisites, fallbacks, or next steps. It also includes a recommended order of execution and a brief reasoning for why each result was returned.\n' +
        '  - If a toolkit has an active connection, the response includes it along with any available current user information. If no active connection exists, the response lists any required parameters for establishing a new one.\n' +
        '  - The response includes the current UTC time for reference. You can reference UTC time from the response if needed.\n' +
        '  - The tools returned to you through this are to be called via RUBE_MULTI_EXECUTE_TOOL. Make sure to specify the tool_slug and arguments for each tool execution properly.\n'
    },
    {
      name: 'RUBE_MANAGE_CONNECTIONS',
      description: '\n' +
        '  MCP Server Info: Rube MCP by Composio connects 500+ apps—Slack, GitHub, Notion, Google Workspace (Gmail, Sheets, Drive, Calendar), Microsoft (Outlook, Teams), X, Figma, Meta apps (WhatsApp, Instagram), TikTok, AI tools like Veo3 & V0, and more—for seamless cross-app automation. Use this MCP server to discover new tools and connect to apps.\n' +
        '<br>\n' +
        "Tool Info: Create/manage connections to user's apps. If RUBE_SEARCH_TOOLS finds no active connection for an app, call this with the toolkit name and required auth params to create one. When the needed params are unclear, the tool returns a list—ask the user for each (e.g. API_KEY). ALWAYS show the list along with their descriptions(if possible) to the user.\n" +
        'If the response includes an OAuth redirect_url, ALWAYS show a FORMATTED MARKDOWN LINK to the user.\n' +
        'Supports OAuth (default/custom), API Key, Bearer Token, Basic Auth, hybrid, and no-auth. Batch-safe, isolates errors, allows selective re-init, returns per-app results and summary.'
    },
    {
      name: 'RUBE_WAIT_FOR_CONNECTION',
      description: '\n' +
        '   Wait for the user to complete authentication after you have given them an auth URL from RUBE_MANAGE_CONNECTIONS. Use this **immediately after** sharing the auth URL so you can automatically continue once the connection is established — without waiting for the user to manually come back and say they’re done. \n' +
        '    This ensures a smooth, uninterrupted flow and a better user experience.\n' +
        '  You NEED NOT wait if there is no auth URL in the response of RUBE_MANAGE_CONNECTIONS like in cases you ask user for  api_key, client_id or client_secret.\n' +
        '    Input params <toolkits: list of toolkit names>, <mode (any / all) : wait for ANY or ALL connections to reach success/failed state (default: any) >\n' +
        '    Output params <connection statuses>\n' +
        '    Example:\n' +
        '    input:\n' +
        '    toolkits: [gmail, outlook]\n' +
        '    mode: [any]\n' +
        '    output: {\n' +
        '      gmail: {\n' +
        '        status: [connected]\n' +
        '      },\n' +
        '      outlook: {\n' +
        '        status: [initiated]\n' +
        '      }\n' +
        '    }\n' +
        '  '
    }
  ]
}
[2025-09-04T14:39:49.664Z] [DEBUG][TOOLS] Successfully initialized server: rube
[2025-09-04T14:39:49.664Z] [DEBUG][TOOLS] MCP Service initialization complete. Total tools available: 33
[2025-09-04T14:39:49.664Z] [DEBUG][APP] MCP service initialized successfully
[2025-09-04T14:39:50.262Z] [DEBUG][KEYBINDS] Shift key pressed, isPressedShiftKey = true
[2025-09-04T14:39:50.486Z] [DEBUG][KEYBINDS] Shift key released, isPressedShiftKey = false
Skip checkForUpdates because application is not packed and dev update config is not forced
[2025-09-04T14:39:53.938Z] [DEBUG][TOOLS] MCP Service initialization starting
[2025-09-04T14:39:53.938Z] [DEBUG][TOOLS] Skipping server github - already initialized
[2025-09-04T14:39:53.938Z] [DEBUG][TOOLS] Skipping server rube - already initialized
[2025-09-04T14:39:53.938Z] [DEBUG][TOOLS] Skipping server desktop-commander - runtime disabled by user
[2025-09-04T14:39:53.938Z] [DEBUG][TOOLS] Found 0 servers to initialize []
[2025-09-04T14:39:53.938Z] [DEBUG][TOOLS] MCP Service initialization complete. Total tools available: 33
[2025-09-04T14:39:53.939Z] [DEBUG][LLM] === LLM CALL START ===
[2025-09-04T14:39:53.939Z] [DEBUG][LLM] Messages → {
  count: 2,
  totalChars: 43006,
  messages: [
    {
      role: 'system',
      content: 'You are an intelligent AI assistant capable of executing tools to help users accomplish complex tasks. You operate autonomously and work iteratively until goals are fully achieved.\n' +
        '\n' +
        'CORE PRINCIPLES:\n' +
        "- Work autonomously until the user's request is completely resolved\n" +
        '- Use available tools iteratively and strategically to gather information and execute actions\n' +
        '- Use exact tool names from the available tools list (including server prefixes like "server:tool_name")\n' +
        '- Prefer using tools to gather information rather than asking users for details\n' +
        "- Continue working until the user's request is fully satisfied - only stop when the task is complete\n" +
        '\n' +
        'TOOL USAGE PHILOSOPHY:\n' +
        '- ALWAYS follow tool schemas exactly as specified with all required parameters\n' +
        '- NEVER call tools that are not explicitly provided in the available tools list\n' +
        '- If you need additional information that you can get via tool calls, prefer that over asking the user\n' +
        '- Use tools proactively to explore and understand the context before making changes\n' +
        '- When making code changes, ensure they can be executed immediately by the user\n' +
        '\n' +
        '# Tone and style\n' +
        'You should be concise, direct, and to the point.\n' +
        'You MUST answer concisely with fewer than 4 lines (not including tool use or code generation), unless user asks for detail.\n' +
        'IMPORTANT: You should minimize output tokens as much as possible while maintaining helpfulness, quality, and accuracy. Only address the specific query or task at hand, avoiding tangential information unless absolutely critical for completing the request. If you can answer in 1-3 sentences or a short paragraph, please do.\n' +
        'IMPORTANT: You should NOT answer with unnecessary preamble or postamble (such as explaining your code or summarizing your action), unless the user asks you to.\n' +
        'Do not add additional code explanation summary unless requested by the user. After working on a file, just stop, rather than providing an explanation of what you did.\n' +
        `Answer the user's question directly, without elaboration, explanation, or details. One word answers are best. Avoid introductions, conclusions, and explanations. You MUST avoid text before/after your response, such as "The answer is <answer>.", "Here is the content of the file..." or "Based on the information provided, the answer is..." or "Here is what I will do next...". Here are some examples to demonstrate appropriate verbosity:\n` +
        '<example>\n' +
        'user: 2 + 2\n' +
        'assistant: 4\n' +
        '</example>\n' +
        '\n' +
        '<example>\n' +
        'user: what is 2+2?\n' +
        'assistant: 4\n' +
        '</example>\n' +
        '\n' +
        '<example>\n' +
        'user: is 11 a prime number?\n' +
        'assistant: Yes\n' +
        '</example>\n' +
        '\n' +
        '<example>\n' +
        'user: what command should I run to list files in the current directory?\n' +
        'assistant: ls\n' +
        '</example>\n' +
        '\n' +
        '<example>\n' +
        'user: what command should I run to watch files in the current directory?\n' +
        'assistant: [use the ls tool to list the files in the current directory, then read docs/commands in the relevant file to find out how to watch files]\n' +
        'npm run dev\n' +
        '</example>\n' +
        '\n' +
        '<example>\n' +
        'user: How many golf balls fit inside a jetta?\n' +
        'assistant: 150000\n' +
        '</example>\n' +
        '\n' +
        '<example>\n' +
        'user: what files are in the directory src/?\n' +
        'assistant: [runs ls and sees foo.c, bar.c, baz.c]\n' +
        'user: which file contains the implementation of foo?\n' +
        'assistant: src/foo.c\n' +
        '</example>\n' +
        '\n' +
        'RESPONSE FORMAT:\n' +
        'For tool calls:\n' +
        '{\n' +
        '  "toolCalls": [\n' +
        '    {\n' +
        '      "name": "exact_tool_name_from_available_list",\n' +
        '      "arguments": { "param1": "value1", "param2": "value2" }\n' +
        '    }\n' +
        '  ],\n' +
        `  "content": "Clear explanation of what you're doing and why",\n` +
        '  "needsMoreWork": true\n' +
        '}\n' +
        '\n' +
        'For final responses (no more tools needed):\n' +
        '{\n' +
        '  "content": "Your comprehensive final response with results",\n' +
        '  "needsMoreWork": false\n' +
        '}\n' +
        '\n' +
        'AGENT MODE - AUTONOMOUS OPERATION:\n' +
        'You can see tool results and make follow-up calls. Work iteratively and thoroughly:\n' +
        '\n' +
        'WORKFLOW:\n' +
        "1. Analyze the user's request comprehensively\n" +
        '2. Gather necessary information using available tools\n' +
        '3. Execute appropriate tools in logical sequence\n' +
        '4. Review results and determine next steps\n' +
        '5. Continue iterating until the goal is fully achieved\n' +
        '6. Only set needsMoreWork: false when the task is completely resolved\n' +
        '\n' +
        '\n' +
        '\n' +
        'AVAILABLE TOOLS:\n' +
        '- github:create_issue: Create a new issue in a GitHub repository\n' +
        '  Parameters: {owner: string (required), repo: string (required), title: string (required), body: string, assignees: array, milestone: number, labels: array}\n' +
        '- github:list_commits: Get list of commits of a branch in a GitHub repository\n' +
        '  Parameters: {owner: string (required), repo: string (required), sha: string, page: number, perPage: number}\n' +
        '- github:list_issues: List issues in a GitHub repository with filtering options\n' +
        '  Parameters: {owner: string (required), repo: string (required), direction: string, labels: array, page: number, per_page: number, since: string, sort: string, state: string}\n' +
        '- github:update_issue: Update an existing issue in a GitHub repository\n' +
        '  Parameters: {owner: string (required), repo: string (required), issue_number: number (required), title: string, body: string, assignees: array, milestone: number, labels: array, state: string}\n' +
        '- github:add_issue_comment: Add a comment to an existing issue\n' +
        '  Parameters: {owner: string (required), repo: string (required), issue_number: number (required), body: string (required)}\n' +
        '- github:search_code: Search for code across GitHub repositories\n' +
        '  Parameters: {q: string (required), order: string, page: number, per_page: number}\n' +
        '- github:search_issues: Search for issues and pull requests across GitHub repositories\n' +
        '  Parameters: {q: string (required), order: string, page: number, per_page: number, sort: string}\n' +
        '- github:get_issue: Get details of a specific issue in a GitHub repository.\n' +
        '  Parameters: {owner: string (required), repo: string (required), issue_number: number (required)}\n' +
        '- github:get_pull_request: Get details of a specific pull request\n' +
        '  Parameters: {owner: string (required), repo: string (required), pull_number: number (required)}\n' +
        '- github:list_pull_requests: List and filter repository pull requests\n' +
        '  Parameters: {owner: string (required), repo: string (required), state: string, head: string, base: string, sort: string, direction: string, per_page: number, page: number}\n' +
        '- rube:RUBE_CREATE_PLAN: \n' +
        'This is a workflow builder that ensures the LLM produces a complete, step-by-step plan for any use case.\n' +
        "You MUST always call this tool after RUBE_SEARCH_TOOLS or RUBE_MANAGE_CONNECTIONS to get a proper execution plan for the user's use case.\n" +
        'If the user pivots to a different use case in same chat, you MUST call this tool again with the new use case.\n' +
        '\n' +
        'Outputs a complete plan with sections such as "workflow_steps", "complexity_assessment", "decision_matrix", "failure_handlig" "output_format", and more as needed. \n' +
        '\n' +
        'If you skip this step, workflows will likely be incomplete, or fail during execution for complex tasks.\n' +
        'Calling it guarantees reliable, accurate, and end-to-end workflows aligned with the available tools and connections.\n' +
        '\n' +
        '  Parameters: {use_case: string (required), known_fields: string (required), primary_tool_slugs: array (required), related_tool_slugs: array, reasoning: string (required), difficulty: string (required)}\n' +
        '- rube:RUBE_MULTI_EXECUTE_TOOL: \n' +
        '  Fast and parallel tool executor for tools discovered through RUBE_SEARCH_TOOLS. Use this tool to execute upto 20 tools in parallel across apps. Response contains structured outputs ready for immediate analysis - avoid reprocessing via remote bash/code execute tools.\n' +
        '  \n' +
        '  Prerequisites:\n' +
        '- Ensure usage of valid tool slugs and their parameters discovered through RUBE_SEARCH_TOOLS.\n' +
        '- Active connection statuses for the tools that are going to be executed through RUBE_MANAGE_CONNECTIONS.\n' +
        '- Ensure proper plan creation using RUBE_CREATE_PLAN has been done.\n' +
        '- Cannot have any dependency of the response among the tools.\n' +
        '\n' +
        'Usage guidelines:\n' +
        '- To be used whenever a tool is discovered and has to be called, either as part of a multi-step workflow or as a standalone tool.\n' +
        '- If RUBE_SEARCH_TOOLS returns a tool that can perform the task, prefer calling it via this executor AFTER consulting RUBE_CREATE_PLAN. Do not write custom API calls or ad‑hoc scripts for tasks that can be completed by available Composio tools.\n' +
        '- Tools should be used highly parallelly.\n' +
        '- Predictively set sync_response_to_workbench=true if the response may be large or needed for later scripting. It still shows inline. However, if the actual response data turns out small and manageable without scripting, SKIP the workbench and use inline response directly.\n' +
        '- Responses contain structured outputs for each tool. RULE: Small data - process yourself inline; large data - process in the workbench.\n' +
        '- ALWAYS include inline references/links to sources in MARKDOWN format directly next to the relevant text. Eg provide slack thread links along with summary. \n' +
        '\n' +
        '  Parameters: {tools: array (required), sync_response_to_workbench: boolean (required), thought: string, current_step: string, current_step_metric: object, next_step: string}\n' +
        '- rube:RUBE_REMOTE_BASH_TOOL: \n' +
        '  Execute bash commands in a REMOTE sandbox for file operations, data processing, and system tasks. Essential for handling large tool responses saved to remote files.\n' +
        '  PRIMARY USE CASES:\n' +
        '- Process large tool responses saved to remote sandbox\n' +
        '- File system operations, data processing with shell tools like jq, awk, sed, grep, etc.\n' +
        '\n' +
        'WORKFLOW INTEGRATION:\n' +
        '1. IF RUBE_MULTI_EXECUTE_TOOL saves large responses to remote sandbox\n' +
        '3. Extract specific information from JSON files using jq\n' +
        '\n' +
        'IMPORTANT NOTES:\n' +
        '- Commands run from /home/user directory by default\n' +
        '\n' +
        '  Parameters: {command: string (required), timeout: any}\n' +
        '- rube:RUBE_REMOTE_WORKBENCH: \n' +
        "  Process REMOTE FILES or script BULK TOOL EXECUTIONS using Python code IN A REMOTE SANDBOX. If you can see the data in chat, DON'T USE THIS TOOL.   \n" +
        '**ONLY** use this when processing **data stored in a remote file** or when scripting bulk Composio tool executions or proxy_execute calls (when no direct Composio tool exists for the task).  \n' +
        '\n' +
        'DO NOT USE\n' +
        '- When the complete response is already inline/in-memory, or you only need '... 32884 more characters
    },
    {
      role: 'user',
      content: 'i want to categorise my emails. collaboration offers under $500 need their own label. determine the other labels yourself.'
    }
  ]
}
[2025-09-04T14:39:53.940Z] [DEBUG][LLM] Creating context manager {
  providerId: 'openai',
  model: 'moonshotai/kimi-k2:free',
  contextLimit: 32768
}
[2025-09-04T14:39:53.940Z] [DEBUG][LLM] Context Manager initialized { maxTokens: 32768, targetTokens: 22937, compressionRatio: 0.3 }
[2025-09-04T14:39:53.940Z] [DEBUG][LLM] Context management: No action needed { currentTokens: 10752, targetTokens: 22937 }
[2025-09-04T14:39:53.941Z] [DEBUG][LLM] Attempting JSON Schema mode for model: moonshotai/kimi-k2:free
[2025-09-04T14:39:53.941Z] [DEBUG][LLM] === OPENAI API REQUEST ===
[2025-09-04T14:39:53.941Z] [DEBUG][LLM] HTTP Request {
  url: 'https://openrouter.ai/api/v1/chat/completions',
  model: 'moonshotai/kimi-k2:free',
  messagesCount: 2,
  responseFormat: {
    type: 'json_schema',
    json_schema: {
      name: 'LLMToolCallResponse',
      description: 'Response format for LLM tool calls with optional tool execution and content',
      schema: [Object],
      strict: true
    }
  },
  estimatedTokens: 10752,
  totalPromptLength: 43006,
  contextWarning: 'WARNING: High token count, may exceed context limit'
}
[2025-09-04T14:39:53.941Z] [DEBUG][LLM] Request Body (truncated) {
  model: 'moonshotai/kimi-k2:free',
  messages: [
    {
      role: 'system',
      content: 'You are an intelligent AI assistant capable of executing tools to help users accomplish complex tasks. You operate autonomously and work iteratively until goals are fully achieved.\n' +
        '\n' +
        'CORE PRINCIPLES:\n' +
        '-... [42884 chars]'
    },
    {
      role: 'user',
      content: 'i want to categorise my emails. collaboration offers under $500 need their own label. determine the other labels yourself.'
    }
  ],
  temperature: 0,
  frequency_penalty: 0.5,
  seed: 1,
  response_format: {
    type: 'json_schema',
    json_schema: {
      name: 'LLMToolCallResponse',
      description: 'Response format for LLM tool calls with optional tool execution and content',
      schema: [Object],
      strict: true
    }
  }
}
